
<!-- ------------------------------------------------------------------ -->
<!-- CHAPTER 1 -->
<!-- <h1><a name="chapter1">CHAPTER 1</a></h1> -->

<h1><a name="chapter1">CHAPTER 1</a></h1> 
<div>
  <p>
    A key requirement for an operating system is to support several
    activities at once. For example, using the system call interface
    described in chapter 0 a process can start new processes with
    {{"fork"|goto_line}} The operating system must <i>time-share</i>
    the resources of the computer among these processes. For example,
    even if there are more processes than there are hardware
    processors, the operating system must ensure that all of the
    processes make progress. The operating system must also arrange
    for <i>isolation</i> between the processes. That is, if one
    process has a bug and fails, it shouldn't affect processes that
    don't depend on the failed process. Complete isolation, however,
    is too strong, since it should be possible for processes to
    interact; pipelines are an example. Thus an operating system must
    fulfill three requirements: multiplexing, isolation, and
    interaction.
  </p>

  <p>
    This chapter provides an overview of how operating systems are
    organized to achieve these 3 requirements. It turns out there are
    many ways to do so, but this text focuses on mainstream designs
    centered around a <i>monolithic kernel</i>, which is used by many
    Unix operating systems. This chapter introduces xv6's design by
    tracing the creation of the first process when xv6 starts running.
    In doing so, the text provides a glimpse of the implementation of
    all major abstractions that xv6 provides, how they interact, and
    how the three requirements of multiplexing, isolation, and
    interaction are met. Most of xv6 avoids special-casing the first
    process, and instead reuses <code>that</code> xv6 must provide for
    standard operation. Subsequent chapters will explore each
    abstraction in more detail.
  </p>
  
  <p>
    Xv6 runs on Intel 80386 or later ("x86") processors on a PC platform, and much
    of its low-level functionality (for example, its process implementation) is
    x86-specific. This book assumes the reader has done a bit of machine-level
    programming on some architecture, and will introduce x86-specific ideas as they
    come up. {{ "A" | appendix }} briefly outlines the PC platform.
    
    <h3> "Abstracting physical resources" </h3>
  <p>
    The first question one might ask when encountering an operating system is why
    have it at all?  That is, one could implement the system calls in
    .figref unix:api
    as a library, with which applications link. In this plan,
    each application could even have its own library tailored to its needs.
    Applications could directly interact with hardware resources
    and use those resources in the best way for the application (e.g., to achieve
    high or predictable performance). Some operating systems for
    embedded devices or real-time systems are organized in this way.
  </p>
  <p>              
    The downside of this library approach is that, if there is more than one
    application running, the applications must be well-behaved.
    For example, each application must periodically give up the
    processor so that other applications can run. Such a <i>cooperative</i>
    time-sharing scheme may be OK if all applications trust each
    other and have no bugs. It's more typical for applications
    to not trust each other, and to have bugs, so one often wants
    stronger isolation than a cooperative scheme provides.
  </p>

  <p>
    To achieve strong isolation it's helpful to forbid applications from
    directly accessing sensitive hardware resources, and instead to abstract the
    resources into services. For example, applications interact with a file system
    only through <code>open</code>, <code>read</code>, <code>write</code>, and <code>close</code>
    system calls, instead of read and writing raw disk sectors. 
    This provides the application with the convenience of pathnames, and it allows
    the operating system (as the implementor of the interface) to manage the disk.
  </p>
  
  <p>
    Similarly, Unix transparently switches hardware processors among processes,
    saving and restoring register state as necessary,
    so that applications don't have to be
    aware of time sharing. This transparency allows the operating system to share
    processors even if some applications are in infinite loops.
  </p>
  
  <p>
    As another example, Unix processes use <code>exec</code> to build up their memory image,
    instead of directly interacting with physical memory.
    This allows the operating system to decide where to place a process in
    memory; if memory is tight, the operating system might even store some of
    a process's data on disk. <code>Exec</code> also provides
    users with the convenience of a file system to store executable program images.
  </p>
  <p>
    Many forms of interaction among Unix processes occur via file
    descriptors.  Not only do file descriptors abstract away many
    details (e.g.  where data in a pipe or file is stored), they also
    are defined in a way that simplifies interaction. For example, if
    one application in a pipeline fails, the kernel generates
    end-of-file for the next process in the pipeline.
  </p>
  <p>
    As you can see, the system call interface in .figref unix:api is
    carefully designed to provide both programmer convenience and the
    possibility of strong isolation. The Unix interface is not the
    only way to abstract resources, but it has proven to be a very
    good one.
  </p>
  <h3>User mode, kernel mode, and system calls</h3>
  
  <p>
    Strong isolation requires a hard boundary between applications and
    the operating system. If the application makes a mistake, we don't
    want the operating system to fail or other applications to
    fail. Instead, the operating system should be able to clean up the
    failed application and continue running other applications.  To
    achieve strong isolation, the operating system must arrange that
    applications cannot modify (or even read) the operating system's
    data structures and instructions and that applications cannot
    access other process's memory.
  </p>
  <p>
    Processors provide hardware support for strong isolation.  For
    example, the x86 processor, like many other processors, has two
    modes in which the processor can execute instructions: <i>kernel
    mode</i> and <i>user mode</i>.  In kernel mode the processor is
    allowed to execute <i>privileged instructions</i>.  For example,
    reading and writing the disk (or any other I/O device) involves
    privileged instructions. If an application in user mode attempts
    to execute a privileged instruction, then the processor doesn't
    execute the instruction, but switches to kernel mode so that the
    software in kernel mode can clean up the application, because it
    did something it shouldn't be doing. .figref unix:os Figure 0-1 in
    in Chapter 0 illustrates this organization. An application can
    execute only user-mode instructions (e.g., adding numbers, etc.)
    and is said to be running in <i>"user space"</i>, while the
    software in kernel mode can also execute privileged instructions
    and is said to be running in <i>"kernel space"</i>.  The software
    running in kernel space (or in kernel mode) is called
    the <i>"kernel"</i>.
  </p>
  <p>
    An application that wants to read or write a file on disk must
    transition to the kernel to do so, because the application itself
    can not execute I/O instructions. Processors provide a special
    instruction that switches the processor from user mode to kernel
    mode and enters the kernel at an entry point specified by the
    kernel. (The x86 processor provides the <code>int</code>
    instruction for this purpose.)  Once the processor has switched to
    kernel mode, the kernel can then validate the arguments of the
    system call, decide whether the application is allowed to perform
    the requested operation, and then deny it or execute it. It is
    important that the kernel sets the entry point for transitions to
    kernel mode; if the application could decide the kernel entry
    point, a malicious application could enter the kernel at a point
    where the validation of arguments etc. is skipped.
    
    <h3>Kernel organization</h3>
  <p>
    A key design question is what part of the operating
    system should run in kernel mode. 
    One possibility is that the entire operating system resides
    in the kernel, so that the implementations of all system calls
    run in kernel mode. This organization is called a <i>monolithic kernel</i>.
  </p>
  <p>
    In this organization the entire operating system runs with full hardware
    privilege. This organization is convenient because the OS designer doesn't have
    to decide which part of the operating system doesn't need full hardware
    privilege. Furthermore, it easy for different parts of the operating system to
    cooperate. For example, an operating system might have a buffer cache that can
    be shared both by the file system and the virtual memory system.
  </p>
  <p>
    A downside of the monolithic organization is that the interfaces between
    different parts of the operating system are often complex (as we will see in the
    rest of this text), and therefore it is easy for an operating system developer
    to make a mistake. In a monolithic kernel, a mistake is fatal, because an error
    in kernel mode will often result in the kernel to fail. If the kernel fails,
    the computer stops working, and thus all applications fail too. The computer
    must reboot to start again.
  </p>
  
  <p>
    To reduce the risk of mistakes in the kernel, OS designers can
    minimize the amount of operating system code that runs in kernel
    mode, and execute the bulk of the operating system in user
    mode. This kernel organization is called a <i>microkernel</i>.
  </p>

  {{ "A microkernel with a file system server" | figure("1-1") }}

  <p>
    Figure 1-1 illustrates this microkernel design. In the figure, the
    file system runs as a user-level process. OS services running as
    processes are called servers. To allow applications to interact
    with the file server, the kernel provides an inter-process
    communication mechanism to send messages from one user-mode
    process to another. For example, if an application like the shell
    wants to read or write a file, it sends a message to the file
    server and waits for a response.
  </p>
  
  <p>
    In a microkernel, the kernel interface consists of a few low-level
    functions for starting applications, sending messages,
    accessing device hardware, etc. This organization allows the kernel to be 
    relatively simple, as most of the operating system
    resides in user-level servers.
  </p>

  <p>
    Xv6 is implemented as a monolithic kernel, following most Unix
    operating systems.  Thus, in xv6, the kernel interface corresponds
    to the operating system interface, and the kernel implements the
    complete operating system. Since xv6 doesn't provide many
    services, its kernel is smaller than some microkernels.
  </p>
  
  {{ "Process overview" | section }}

  <p>
    The unit of isolation in xv6 (as in other Unix operating systems)
    is a <i>"process"</i>. The process abstraction prevents one
    process from wrecking or spying on another process's memory, CPU,
    file descriptors, etc. It also prevents a process from wrecking
    the kernel itself, so that a process can't subvert the kernel's
    isolation mechanisms. The kernel must implement the process
    abstraction with care because a buggy or malicious application may
    trick the kernel or hardware in doing something bad (e.g.,
    circumventing enforced isolation). The mechanisms used by the
    kernel to implement processes include the user/kernel mode flag,
    address spaces, and time-slicing of threads.
  </p>

  <p>
    To help enforce isolation, the process abstraction provides the
    illusion to a program that it has its own private machine. A process provides
    a program with what appears to be a private memory system, or
    <i>"address space"</i>, which other processes cannot read or write.
    A process also provides the program with what appears to be its own
    CPU to execute the program's instructions.
  </p>

  <p>
    Xv6 uses page tables (which are implemented by hardware) to give
    each process its own address space. The x86 page table translates
    (or "maps") a <i>"virtual address"</i>(the address that an x86
    instruction manipulates) to a <i>"physical address"</i> (an
    address that the processor chip sends to main memory).
  </p>

  <br>
  <img src="figs/fig1-2.jpg" alt="figure 1" class="img-thumbnail">
  <center>
    Figure 1-2. <small class="text-muted">Layout of a virtual address space</small>
  </center>
  <br>

  <p>
    Xv6 maintains a separate page table for each process that defines
    that process's address space. As illustrated in .figref as , an
    address space includes the process's <i>"user memory"</i> starting
    at virtual address zero. Instructions come first, followed by
    global variables, then the stack, and finally a "heap" area (for
    malloc) that the process can expand as needed.
  </p>

  <p>
    Each process's address space maps the kernel's instructions and
    data as well as the user program's memory.  When a process invokes
    a system call, the system call executes in the kernel mappings of
    the process's address space.  This arrangement exists so that the
    kernel's system call code can directly refer to user memory.  In
    order to leave plenty of room for user memory, xv6's address
    spaces map the kernel at high addresses, starting at
    <code>0x80100000 .</code>
  </p>
  
  <p>
    The xv6 kernel maintains many pieces of state for each process,
    which it gathers into a {{ "struct proc" | goto_line }}
    A process's most important pieces of kernel state are its 
    page table, its kernel stack, and its run state.
    We'll use the notation <code>p->xxx</code> to refer to elements of the
    <code>proc</code> structure.
  </p>
  
  <p>
    Each process has a thread of execution (or <i>thread</i> for
    short) that executes the process's instructions. A thread can be
    suspended and later resumed. To switch transparently between
    processes, the kernel suspends the currently running thread and
    resumes another process's thread. Much of the state of a thread
    (local variables, function call return addresses) is stored on the
    thread's stacks. Each process has two stacks: a user stack and a
    kernel stack (<code>p->kstack</code>). When the process is
    executing user instructions, only its user stack is in use, and
    its kernel stack is empty. When the process enters the kernel (for
    a system call or interrupt), the kernel code executes on the
    process's kernel stack; while a process is in the kernel, its user
    stack still contains saved data, but isn't actively used. A
    process's thread alternates between actively using its user stack
    and its kernel stack. The kernel stack is separate (and protected
    from user code) so that the kernel can execute even if a process
    has wrecked its user stack.
  </p>

  <p>
    When a process makes a system call, the processor switches to the
    kernel stack, raises the hardware privilege level, and starts
    executing the kernel instructions that implement the system call.
    When the system call completes, the kernel returns to user space:
    the hardware lowers its privilege level, switches back to the user
    stack, and resumes executing user instructions just after the
    system call instruction. A process's thread can "block" in the
    kernel to wait for I/O, and resume where it left off when the I/O
    has finished.
  </p>
  
  <p>
    <code>p->state</code> indicates whether the process is allocated, ready
    to run, running, waiting for I/O, or exiting.
  </p>
  
  <p>
    <code>p->pgdir</code> holds the process's page table, in the
    format that the x86 hardware expects.  xv6 causes the paging
    hardware to use a process's memory <code>p->pgdir</code> when
    executing that process. A process's page table also serves as the
    record of the addresses of the physical pages allocated to store
    the process's memory.
  </p>
  
  {{ "Code: the first address space" | section }}

  <p>
    To make the xv6 organization more concrete, we'll look how the
    kernel creates the first address space (for itself), how the
    kernel creates and starts the first process, and how that process
    performs the first system call. By tracing these operations we see
    in detail how xv6 provides strong isolation for processes.  The
    first step in providing strong isolation is setting up the kernel
    to run in its own address space.
  </p>
  
  <p>
    When a PC powers on, it initializes itself and then loads a
    <i>boot loader</i> from disk into memory and executes it. {{ "B" | appendix }}
    explains the details. Xv6's boot loader loads the xv6
    kernel from disk and executes it starting at {{ "entry" | goto_line }}.
    The x86 paging hardware is not enabled when the kernel starts;
    virtual addresses map directly to physical addresses.
  </p>
  
  <p>
    The boot loader loads the xv6 kernel into memory at physical address
    <code>0x100000</code>.
    The reason it doesn't load the kernel at
    <code>0x80100000</code> ,
    where the kernel expects to find its instructions and data,
    is that there may not be any physical memory at such
    a high address on a small machine.
    The reason it places the kernel at
    <code>0x100000</code>
    rather than
    <code>0x0</code>
    is because the address range
    <code>0xa0000:0x100000</code>
    contains I/O devices.
    .figure astmp
  </p>
  
  <p>
    To allow the rest of the kernel to run,
    <code>entry</code>
    sets up a page table that maps virtual addresses starting at
    <code>0x80000000</code>
    (called <code><a href="javascript:gotoLine(207);">KERNBASE</a></code>)
    to physical addresses starting at
    <code>0x0</code>
    (see .figref as ).
    Setting up two ranges of virtual addresses that map to the same physical memory
    range is a common use of page tables, and we will see more examples like this
    one.
  </p>

  <p>
    The entry page table is defined in main.c
    .line 'main.c:/^pde_t.entrypgdir.*=/' .
    We look at the details of page tables in Chapter  \*[CH:MEM],
    but the short story is that entry 0 maps virtual addresses
    <code>0:0x400000</code>
    to physical addresses
    <code>0:0x400000</code>.
    This mapping is required as long as
    <a href="javascript:gotoLine(1044);"><code>entry</code></a>
    is executing at low addresses, but
    will eventually be removed.
  </p>
  
  <p>
    Entry 512 maps virtual
    addresses <code>KERNBASE:KERNBASE+0x400000</code> to physical
    addresses <code>0:0x400000</code>. This entry will be used by the
    kernel
    after <a href="javascript:gotoLine(1044);"><code>entry</code></a>
    has finished; it maps the high virtual addresses at which the
    kernel expects to find its instructions and data to the low
    physical addresses where the boot loader loaded them. This
    mapping restricts the kernel instructions and data to 4 Mbytes.
  </p>

  <p>
    Returning to
    <a href="javascript:gotoLine(1044);"><code>entry</code></a>
    it loads the physical address of
    <code>entrypgdir</code>
    into control register
    <code>%cr3</code>.
    The value in
    <code>%cr3</code>
    must be a physical address.
    It wouldn't make sense for
    <code>%cr3</code>
    to hold the virtual address of
    <code>entrypgdir</code>,
    because the paging hardware 
    doesn't know how to translate virtual addresses yet; it
    doesn't have a page table yet.
    The symbol
    <code>entrypgdir</code>,
    refers to an address in high memory,
    and the macro
    <a href="javascript:gotoLine(213);"><code>V2P_WO</code></a>
    <!-- .line 'memlayout.h:/V2P_WO/'  -->
    subtracts
    <code>KERNBASE</code>
    in order to find the physical address.
    To enable the paging hardware, xv6 sets the flag
    <a href="javascript:gotoLine(709);"><code>CR0_PG</code></a>
    in the control register
    <code>%cr0</code>
  </p>

  <p>
    The processor is still executing instructions at low addresses
    after paging is enabled, which works since <code>entrypgdir</code>
    maps low addresses.  If xv6 had omitted entry 0
    from <code>entrypgdir</code>, the computer would have crashed when
    trying to execute the instruction after the one that enabled
    paging.
  </p>

  <p>
    Now {{ "entry" | goto_line }} needs to transfer to the kernel's C
    code, and run it in high memory.  First it makes the stack
    pointer, <code>%esp</code>, point to memory to be used as a stack
    .line entry.S:/movl.*stack.*esp/ .  All symbols have high
    addresses, including <code>stack ,</code> so the stack will still
    be valid even when the low mappings are removed.  Finally
    <code>entry</code> jumps to <code>main ,</code> which is also a
    high address. The indirect jump is needed because the assembler
    would otherwise generate a PC-relative direct jump, which would
    execute the low-memory version
    of <code>main</code>. <code>Main</code> cannot return, since the
    there's no return PC on the stack.  Now the kernel is running in
    high addresses in the function {{ "main" | goto_line }}.
  </p>
  
  <h4>§ Code: creating the first process</h4>
  
  <p>
    Now we'll look at how the kernel
    creates user-level processes and ensures that they are strongly isolated.
  </p>
  
  <p>
    After
    <a href="javascript:gotoLine(1217);"><code class="">main</code></a> 
    initializes several devices and subsystems, 
    it creates the first process by calling
    <a href="javascript:gotoLine(2520);"><code class="">userinit</code></a>, 
    <code>Userinit</code>'s
    first action is to call
    <a href="javascript:gotoLine(2473);"><code class="">allocproc</code></a>, 
    The job of
    is to allocate a slot
    <a href="javascript:gotoLine(2337);"><code>struct proc</code></a>
    in the process table and
    to initialize the parts of the process's state
    required for its kernel thread to execute.
    <code>Allocproc</code> is called for each new process, while
    <a href="javascript:gotoLine(2520);"><code>userinit</code></a> 
    is called only for the very first process.
    <code>Allocproc</code>
    scans the 
    <code>proc</code>
    table for a slot with state
    <a href="javascript:gotoLine(2480);"><code>UNUSED</code></a> 
    When it finds an unused slot, 
    <a href="javascript:gotoLine(2473);"><code class="">allocproc</code></a>
    sets the state to
    <code>EMBRYO</code>
    to mark it as used and
    gives the process a unique
    <a href="javascript:gotoLines(2469, 2489);"><code class="">pid</code></a>, 
    
    Next, it tries to allocate a kernel stack for the
    process's kernel thread. If the memory allocation fails, 
    <code>allocproc</code>
    changes the state back to
    <code>UNUSED</code>
    and returns zero to signal failure.
    
    <a name="fig1-4"></a>
    <br/>
    <br/>
    <img src="figs/fig1-4.jpg" alt="figure 1-4" class="img-thumbnail">
    
    <center><i>figure 1-4. A new kernel stack.</i></center>
    <br/>
    
  <p>
    Now <code>allocproc</code> must set up the new process's kernel stack.
    <code>allocproc</code>
    is written so that it can be used by 
    <code>fork</code>
    as well
    as when creating the first process.
    <code>allocproc</code> sets up the new process with a
    specially prepared kernel stack and set of kernel
    registers that cause it to "return" to user space when
    it first runs. The layout of the prepared kernel stack
    will be as shown in <b>figure 1-4</b>. <code>allocproc</code>
    does part of this work by setting up return program
    counter values that will cause the new process's kernel
    thread to first execute in {{"forkret"|goto_line}} and then
    in <a href="javascript:gotoLines(2507,2512);"><code>trapret.</code></a>
    
    The kernel thread will start executing with register contents copied from
    <code>p->context.</code> Thus setting <code>p->context->eip</code> 
    to <code>forkret</code> will cause the kernel thread to execute at
    the start of <a href="javascript:gotoLine(2853);"><code>forkret</code></a>.
    
    This function will return to whatever address is at the bottom of
    the stack. The <a href="javascript:gotoLine(3058);">context
    switch code</a> sets the stack pointer to point just beyond the
    end of <code>p->context.</code>
    <code>allocproc</code> places <code>p->context</code> on the stack, and puts a pointer to
    <code>trapret</code> just above it; that is where <code>forkret</code> 
    will return. <code>trapret</code> restores user registers
    from values stored at the top of the kernel stack and jumps
    into the <a href="javascript:gotoLine(3324);">process</a>
    This setup is the same for ordinary <code>fork</code> 
    and for creating the first process, though in
    the latter case the process will start executing at
    user-space location zero rather than at a return from
    <code>fork.</code> 
  </p>

  <p>
    As we will see in Chapter 3, the way that control transfers from
    user software to the kernel is via an interrupt mechanism, which
    is used by system calls, interrupts, and exceptions. Whenever
    control transfers into the kernel while a process is running, the
    hardware and xv6 trap entry code save user registers on the
    process's kernel stack. <code>userinit</code> writes values at the
    top of the new stack that look just like those that would be there
    if the process had entered the kernel via an {{ "interrupt" |
    goto_lines(2533, 2540) }} so that the ordinary code for returning
    from the kernel back to the process's user code will work. These
    values are a
    <code>struct trapframe</code> 
    which stores the user registers. Now the new process's kernel stack is
    completely prepared as shown in             

    <a class="popoverOption" href="#fig1-4" data-content="<img src='figs/fig1-4.jpg' alt='figure 1-4'>"
       rel="popover" data-placement="bottom" data-original-title="Figure 1-4">Figure 1-4</a>.

  </p>


  <p>
    The first process is going to execute a small program
    (<a href="javascript:gotoLine(8400);">initcode.S</a>).
    The process needs physical memory in which to store this
    program, the program needs to be copied to that memory,
    and the process needs a page table that maps user-space addresses to
    that memory.
    
  </p>
  <p>
    
    <code>userinit</code> calls <code><a href="javascript:gotoLine(1818);">setupkvm</a></code>
    to create a page table for the process with (at first) mappings
    only for memory that the kernel uses.
    We will study this function in detail in Chapter 2, but
    at a high level <code>setupkvm</code> and <code>userinit </code> 
    create an address space
    as shown in

    <a class="popoverOption" href="#fig1-2" data-content="<img src='figs/fig1-2.jpg' alt='figure 1-2'>"
       rel="popover" data-placement="bottom" data-original-title="Figure 1-2">Figure 1-2</a>.

  </p>

  <p>
    The initial contents of the first process's user-space memory are
    the compiled form of
    <code>initcode.S ;</code> 
    as part of the kernel build process, the linker
    embeds that binary in the kernel and
    defines two special symbols,
    <code>_binary_initcode_start</code> 
    and
    <code>_binary_initcode_size ,</code> 
    indicating the location and size of the binary.
    <code>Userinit</code> 
    copies that binary into the new process's memory
    by calling
    <code>inituvm ,</code> 
    which allocates one page of physical memory,
    maps virtual address zero to that memory,
    and copies the binary to that page
    .line vm.c:/^inituvm/ .

  </p><p>
    Then 
    <code>userinit</code>
    sets up the trap frame
    .line x86.h:/^struct.trapframe/
    with the initial user mode state:
    the
    .register cs
    register contains a segment selector for the
    <code>SEG_UCODE</code> 
    segment running at privilege level
    <code>DPL_USER</code> 
    (i.e., user mode rather than kernel mode),
    and similarly
    .register ds ,
    .register es ,
    and
    .register ss
    use
    <code>SEG_UDATA</code> 
    with privilege
    <code>DPL_USER .</code> 
    The
    .register eflags
    <code>FL_IF</code> 
    bit is set to allow hardware interrupts;
    we will reexamine this in Chapter \*[CH:TRAP].

  </p><p>
    The stack pointer 
    .register esp
    is set to the process's largest valid virtual address,
    <code>p->sz.</code> 
    The instruction pointer is set to the entry point
    for the initcode, address 0.

  </p><p>
    The function
    <code>userinit</code> 
    sets
    <code>p->name</code> 
    to
    <code>"initcode"</code> 
    mainly for debugging.
    Setting
    <code>p->cwd</code> 
    sets the process's current working directory;
    we will examine
    <code>namei</code> 
    in detail in Chapter \*[CH:FS].
  </p><p>
    Once the process is initialized,
    <code>userinit</code> 
    marks it available for scheduling by setting 
    <code>p->state</code> 
    to
    <code>RUNNABLE.</code>

    
    .\"
    .section "Code: Running the first process"
    .\"
    
    Now that the first process's state is prepared, it is time
    to run it. After <code>main</code> calls
    <code>userinit,</code> 
    <code>mpmain</code> 
    calls
    <code>scheduler</code> 
    to start running processes
    .line main.c:/scheduler/ .
    <code>Scheduler</code> 
    .line proc.c:/^scheduler/
    looks for a process with
    <code>p->state</code> 
    set to
    <code>RUNNABLE ,</code> 
    and there's only one:
    <code>initproc .</code> 
    It sets the per-cpu variable
    <code>proc</code> 
    to the process it found and calls
    <code>switchuvm</code> 
    to tell the hardware to start using the target
    process's page table
    .line vm.c:/lcr3.*V2P.p..pgdir/ .
    Changing page tables while executing in the kernel
    works because 
    <code>setupkvm</code> 
    causes all processes' page tables to have identical
    mappings for kernel code and data.
    <code>switchuvm</code> 
    also sets up a task state segment
    <code>SEG_TSS</code> 
    that instructs the hardware to
    execute system calls and interrupts
    on the process's kernel stack.
    We will re-examine the task state segment in Chapter \*[CH:TRAP].

  </p><p>
    <code>scheduler</code> 
    now sets
    <code>p->state</code> 
    to
    <code>RUNNING</code> 
    and calls
    <code>swtch</code> 
    .line swtch.S:/^swtch/ 
    to perform a context switch to the target process's kernel thread.
    <code>swtch </code> 
    first saves the current registers.
    The current context is not a process but rather a special
    per-cpu scheduler context, so
    <code>scheduler</code> 
    tells
    <code>swtch</code> 
    to save the current hardware registers in per-cpu storage
    <code>cpu->scheduler ) (</code> 
    rather than in any process's kernel thread context.
    <code>swtch</code> 
    then loads the saved registers
    of the target kernel thread
    <code>p->context ) (</code> 
    into the x86 hardware registers,
    including the stack pointer and instruction pointer.
    We'll examine
    <code>swtch</code> 
    in more detail in Chapter \*[CH:SCHED].
    The final
    <code>ret</code> 
    instruction 
    .line swtch.S:/ret$/
    pops the target process's
    .register eip
    from the stack, finishing the context switch.
    Now the processor is running on the kernel stack of process
    <code>p .</code> 
  </p><p>
    <code>Allocproc</code> 
    had previously set
    <code>initproc 's</code> 
    <code>p->context->eip</code> 
    to
    <code>forkret ,</code> 
    so the 
    <code>ret</code> 
    starts executing
    <code>forkret .</code> 
    On the first invocation (that is this one),
    <code>forkret</code> 
    .line proc.c:/^forkret/
    runs initialization functions that cannot be run from 
    <code>main </code> 
    because they must be run in the context of a regular process with its own
    kernel stack. 
    Then, 
    <code>forkret </code> 
    returns.
    <code>Allocproc</code> 
    arranged that the top word on the stack after
    <code>p->context</code> 
    is popped off
    would be 
    <code>trapret ,</code> 
    so now 
    <code>trapret</code> 
    begins executing,
    with 
    .register esp
    set to
    <code>p->tf .</code> 
    <code>Trapret</code> 
    .line trapasm.S:/^trapret/ 
    uses pop instructions to restore registers from
    the trap frame
    .line x86.h:/^struct.trapframe/
    just as 
    <code>swtch</code> 
    did with the kernel context:
    <code>popal</code> 
    restores the general registers,
    then the
    <code>popl </code> 
    instructions restore
    .register gs ,
    .register fs ,
    .register es ,
    and
    .register ds .
    The 
    <code>addl</code> 
    skips over the two fields
    <code>trapno</code> 
    and
    <code>errcode .</code> 
    Finally, the
    <code>iret</code> 
    instruction pops 
    .register cs ,
    .register eip ,
    .register flags ,
    .register esp ,
    and
    .register ss
    from the stack.
    The contents of the trap frame
    have been transferred to the CPU state,
    so the processor continues at the
    .register eip
    specified in the trap frame.
    For
    <code>initproc ,</code> 
    that means virtual address zero,
    the first instruction of
    <code>initcode.S .</code> 
  </p><p>
    At this point,
    .register eip
    holds zero and
    .register esp
    holds 4096.
    These are virtual addresses in the process's address space.
    The processor's paging hardware translates them into physical addresses.
    <code>allocuvm</code> 
    has set up the process's page table so that virtual address
    zero refers
    to the physical memory allocated for this process,
    and set a flag
    <code>PTE_U ) (</code> 
    that tells the paging hardware to allow user code to access that memory.
    The fact that
    <code>userinit</code> 
    .line proc.c:/UCODE/
    set up the low bits of
    .register cs
    to run the process's user code at CPL=3 means that the user code
    can only use pages with
    <code>PTE_U</code> 
    set, and cannot modify sensitive hardware registers such as
    .register cr3 .
    So the process is constrained to using only its own memory.
    .\"
    .section "The first system call: exec"
    .\"
  </p><p>
    Now that we have seen how the kernel provides strong isolation for processes, let's
    look at how a user-level process re-enters the kernel to ask for services
    that it cannot perform itself.
  </p><p>
    The first action of 
    <code>initcode.S</code> 
    is to invoke  the
    <code>exec</code> 
    system call.
    As we saw in Chapter \*[CH:UNIX], 
    <code>exec</code> 
    replaces the memory and registers of the
    current process with a new program, but it leaves the
    file descriptors, process id, and parent process unchanged.
  </p><p>
    <code>Initcode.S</code>.
    line initcode.S:/^start/
    begins by pushing three values
    on the stack-\c
    <code>$argv ,</code> 
    <code>$init ,</code> 
    and
    <code>$0 -\c</code> 
    and then sets
    .register eax
    to
    <code>SYS_exec</code> 
    and executes
    <code>int</code> 
    <code>T_SYSCALL :</code> 
    it is asking the kernel to run the
    <code>exec</code> 
    system call.
    If all goes well,
    <code>exec</code> 
    never returns: it starts running the program 
    named by
    <code>$init ,</code> 
    which is a pointer to
    the NUL-terminated string
    <code>"/init"</code> 
    .line initcode.S:/init.0/,/init.0/ .
    The other argument is the
    <code>argv</code> 
    array of command-line arguments; the zero at the
    end of the array marks its end.
    If the
    <code>exec</code> 
    fails and does return,
    initcode
    loops calling the
    <code>exit</code> 
    system call, which definitely
    should not return
    .line initcode.S:/for.*exit/,/jmp.exit/ .
  </p><p>
    This code manually crafts the first system call to look like
    an ordinary system call, which we will see in Chapter \*[CH:TRAP]. As
    before, this setup avoids special-casing the first process (in this
    case, its first system call), and instead reuses code that xv6 must
    provide for standard operation.
    
  </p>
  <p>

    Chapter {{"MEM" | chapter}} will cover the implementation
    of <code>exec </code> in detail, but at a high level it replaces
    <code>initcode </code> with the <code>/init</code> binary, loaded
    out of the file system. Now <code>initcode</code> .line
    initcode.S:1 is done, and the process will run <code>/init</code>
    instead. <code>Init</code> .line init.c:/^main/ creates a new
    console device file if needed and then opens it as file
    descriptors 0, 1, and 2. Then it loops, starting a console shell,
    handles orphaned zombies until the shell exits, and repeats. The system is up.

    {{ "Real world" | section }}
    
  </p><p>
    
    In the real world, one can find both monolithic kernels and
    microkernels. Many Unix kernels are monolithic. For example, Linux
    has a monolithic kernel, although some OS functions run as
    user-level servers (e.g., the windowing system). Kernels such as
    L4, Minix, QNX are organized as a microkernel with servers, and
    have seen wide deployment in embedded settings.
    
  </p><p>
    Most operating systems have adopted the process
    concept, and most processes look similar to xv6's.
    A real operating system would find free
    <code>proc</code> 
    structures with an explicit free list
    in constant time instead of the linear-time search in
    <code>allocproc</code>;
    xv6 uses the linear scan
    (the first of many) for simplicity.
  </p>

  {{ "Exercises" | section }}
  
  <p>
    1. Set a breakpoint at swtch. Single step with
    gdb's <code>stepi</code> through the ret to
    <code>forkret</code>, then use gdb's <code>finish</code> to
    proceed to <code>trapret</code>, then <code>stepi</code> until you
    get to <code>initcode</code> at virtual address zero.
  </p>

  <p>
    2. <code>KERNBASE</code> limits the amount of memory a single
    process can use, which might be irritating on a machine with a
    full 4 GB of RAM. Would raising <code>KERNBASE</code> allow a
    process to use more memory?
  </p>
    
    
</div> <!-- end chapter1 -->
